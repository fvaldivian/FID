---
title: "R Notebook"
output: html_notebook
---
```{r}

```

```{r}
library(rpart)
library(psych)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(lubridate)
library(C50)
library(gmodels)
library(OneR)
```


```{r}
retail<-  read_csv("archive (1)/supermarket_sales - Sheet1.csv")
head(retail)
```

First, the date variable needs to be properly encoded to be recognized.

Then, the dataset is split into a separate dataset for each branch.


```{r}
retail$Date <- gsub('/', '-', retail$Date)

r2 <- retail %>% 
  mutate(DATE=mdy(Date))%>%
  select(everything())
```


```{r}
retailA<- filter(r2, Branch=='A')
retailB<- filter(r2, Branch=='B')
retailC<- filter(r2, Branch=='C')
```


```{r}

head(retailA)
colnames(retail)
```

ÁRBOL DE DECISION C5.0: lo voy a utilizar para determinar si hay variables significativas para predecir la puntuación que el cliente le da a la tienda.


We need to find a target variable first. We will examing rating. Need to encode raiting as yes or no for deicion tree. Decide 8.5 is good rating, below is bad. Arbitrary
```{r}
summary(retail$Rating)
```


```{r}
retail2<-mutate(retail,
      goodrating= ifelse(Rating>7.5, "Yes", "No"))

retail2$goodrating <- as.factor(retail2$goodrating)

retail2$Time <- gsub(':', '.', retail2$Time)
```


```{r}
retail2 <- select(retail2, -(Rating))
retail2 <- select(retail2, -(Time))
```


```{r}
retail2 <- retail2 %>% 
  mutate(DATE=mdy(Date))%>%
  select(everything())
```


```{r}
retail2 <- select(retail2, -(Date))
retail2 <- retail2 %>%
  mutate(
    Month=month(DATE)
  )
retail2
```


```{r}
retail2 <- select(retail2, -(DATE))
```


```{r}
retail3<-select(retail2, Branch,'Customer type', Gender, 'Product line', 'Unit price', Quantity, Total, Month, goodrating)

```

Dividir los datos en conjunto de entrenamiento y prueba
```{r}

set.seed(123)
indices_entrenamiento <- sample(1:nrow(retail3), 0.8 * nrow(retail3))
retail_train<- retail3[indices_entrenamiento, ]
retail_test <- retail3[-indices_entrenamiento, ]


```


```{r}
prop.table(table(retail_test$goodrating))
prop.table(table(retail_train$goodrating))
```


```{r}
retail_model <- C5.0(retail_train[-9], retail_train$goodrating)

retail_model

retail_pred <- predict(retail_model, retail_test)

CrossTable(retail_test$goodrating, retail_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```

The end result of this ML analysis is not very good. However, it appears that the predictions of no is twice as likely as a false positive. Thus, it is worth examining the trees to find why no.
```{r}
summary(retail_model)
```

Eso de arriba es el árbol de decisión al completo.
Estructura del árbol: Cada rama del árbol representa una regla de decisión basada en las variables predictoras. Por ejemplo, en la primera división, si el producto pertenece a la línea "Electronic accessories", se hace una subdivisión adicional basada en las variables como "Branch", "Quantity", "Total", y "Gender", entre otros.

Clasificaciones: El árbol clasifica las observaciones en diferentes categorías. Por ejemplo, si el producto es "Electronic accessories", dependiendo de los valores de las variables, el árbol predice si la calificación será "No" o "Yes" para "goodrating".

Errores del modelo: El árbol tiene un tamaño de 109 nodos y cometió errores en el 19% de las predicciones realizadas en el conjunto de entrenamiento. De las 800 observaciones, 152 fueron clasificadas incorrectamente.

Uso de atributos: Se muestra qué porcentaje del tiempo se usó cada atributo para hacer divisiones en el árbol. Por ejemplo, "Product line" se usó el 100% del tiempo para tomar decisiones, mientras que "Quantity" se usó el 20.38% del tiempo.

Estos resultados muestran cómo el modelo de árbol de decisión divide el espacio de características para predecir la variable objetivo (goodrating) basándose en las características proporcionadas en el conjunto de datos de entrenamiento. 

En resumen, las tres principales características en las que se basan los clientes para dar una buena puntuación ( por encima del 8.5) son: 
100.00%	Product line
	 91.13%	Branch
	 67.50%	Customer type
```{r}
```


```{r}
```


